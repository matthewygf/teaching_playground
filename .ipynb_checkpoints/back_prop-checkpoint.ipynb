{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q is 3\n",
      "z is -4\n",
      "dfdz is 3\n",
      "dfdq is -4\n",
      "dfdy is -4\n",
      "dfdx is -4\n"
     ]
    }
   ],
   "source": [
    "# f(x,y,z) = (x + y)z\n",
    "x = -2\n",
    "y = 5\n",
    "z = -4\n",
    "\n",
    "q = x + y\n",
    "f = q * z\n",
    "\n",
    "dfdz = q\n",
    "dfdq = z\n",
    "\n",
    "dfdy = 1 * dfdq \n",
    "dfdx = 1 * dfdq\n",
    "\n",
    "print (\"q is %d\" % q)\n",
    "print (\"z is %d\" % z)\n",
    "\n",
    "print (\"dfdz is %d\" % dfdz)\n",
    "print (\"dfdq is %d\" % dfdq)\n",
    "\n",
    "print (\"dfdy is %d\" % dfdy)\n",
    "print (\"dfdx is %d\" % dfdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3932238664829637, -0.5898357997244456]\n",
      "[-0.19661193324148185, -0.3932238664829637, 0.19661193324148185]\n"
     ]
    }
   ],
   "source": [
    "# f(w,x) = 1 / (1 + math.exp(- (w0*x0 + w1*x1 + w2)))\n",
    "\n",
    "w = [2, -3, -3]\n",
    "x = [-1, -2]\n",
    "\n",
    "# forward pass\n",
    "weightedsum = w[0] * x[0] + w[1] * x[1] + w[2]\n",
    "f = 1 / (1 + math.exp(-weightedsum))\n",
    "\n",
    "# backward pass\n",
    "dfdweightedsum = (1 - f) * f # gradient on the weighted sum, because that is the sigmoid activation derivation\n",
    "dx = [w[0] * dfdweightedsum, w[1] * dfdweightedsum]\n",
    "dw = [x[0] * dfdweightedsum, x[1]* dfdweightedsum, 1.0 * dfdweightedsum]\n",
    "\n",
    "print (dx)\n",
    "print (dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    # we almost always want the weights to be gaussian distribution\n",
    "    # but we will play with the normal method and see what are the effects.\n",
    "    weights = tf.(shape, seed=SEED, stddev=1.0) \n",
    "    return tf.Variable(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_data():\n",
    "    \"\"\" Read iris data and split \"\"\"\n",
    "    iris = datasets.load_iris()\n",
    "    input_data = iris[\"data\"]\n",
    "    labels = iris[\"target\"]\n",
    "    \n",
    "    # convert to one-hot vectors\n",
    "    oh_y = np.eye(len(np.unique(labels)))[labels]\n",
    "    # split the data set into train and test set because YOLO\n",
    "    return train_test_split(input_data, oh_y, test_size=0.33, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape has (100, 4) \n",
      "testing shape has (50, 4)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = get_iris_data()\n",
    "print(\"training shape has %s \" % str(train_X.shape))\n",
    "print(\"testing shape has %s\" % str(test_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 31.00%, test accuracy=38.00%\n",
      "Epoch = 101, train accuracy = 65.00%, test accuracy=70.00%\n",
      "Epoch = 201, train accuracy = 66.00%, test accuracy=72.00%\n",
      "Epoch = 301, train accuracy = 87.00%, test accuracy=90.00%\n",
      "Epoch = 401, train accuracy = 95.00%, test accuracy=100.00%\n",
      "Epoch = 501, train accuracy = 96.00%, test accuracy=98.00%\n",
      "Epoch = 601, train accuracy = 96.00%, test accuracy=98.00%\n",
      "Epoch = 701, train accuracy = 96.00%, test accuracy=98.00%\n",
      "Epoch = 801, train accuracy = 97.00%, test accuracy=98.00%\n",
      "Epoch = 901, train accuracy = 97.00%, test accuracy=100.00%\n"
     ]
    }
   ],
   "source": [
    "# Input neurons should be 4 , beacause the data set x features are 4.\n",
    "# output neruons are 3 , because iris has 3 classes\n",
    "input_neurons = 4\n",
    "hidden_neurons = 4\n",
    "output_neurons = 3\n",
    "\n",
    "# init our data_placeholder \n",
    "# init to None for tf to determine at runtime \n",
    "input_x = tf.placeholder(tf.float32, shape=[None, input_neurons], name='inputs')\n",
    "label_y = tf.placeholder(tf.float32, shape=[None, output_neurons], name='ouputs')\n",
    "\n",
    "# initialise our Variables\n",
    "w1 = init_weights([input_neurons, hidden_neurons]) # first layer -> hidden\n",
    "b1 = init_weights([hidden_neurons])\n",
    "\n",
    "w2 = init_weights([hidden_neurons, output_neurons]) # hidden -> ouput\n",
    "b2 = init_weights([output_neurons])\n",
    "\n",
    "# forward pass\n",
    "hidden_ouput = tf.nn.sigmoid(tf.add(tf.matmul(input_x, w1), b1))\n",
    "final_output = tf.add(tf.matmul(hidden_ouput, w2), b2)\n",
    "\n",
    "# backward pass\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label_y, logits=final_output))\n",
    "update_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "# define out prediction op\n",
    "predict_op = tf.argmax(final_output, axis=1)\n",
    "\n",
    "# start init all the variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # batch training\n",
    "    sess.run(update_op, feed_dict={input_x: train_X, label_y: train_Y})\n",
    "    if epoch % 100 == 0 :\n",
    "        prediction = sess.run(predict_op, feed_dict={input_x: train_X, label_y: train_Y})\n",
    "        test_prediction = sess.run(predict_op, feed_dict={input_x: test_X, label_y: test_Y})\n",
    "        train_accuracy = np.mean(np.argmax(train_Y, axis=1) == prediction)\n",
    "        test_accuracy = np.mean(np.argmax(test_Y, axis=1) == test_prediction)\n",
    "        print (\"Epoch = %d, train accuracy = %.2f%%, test accuracy=%.2f%%\" \n",
    "               % (epoch +1, 100 * train_accuracy, 100 * test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
